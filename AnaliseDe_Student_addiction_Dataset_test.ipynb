{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW3mlDs5FpHlBSVlcsBJEL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eddieHerman-lab/Analise_DE_Diamantes/blob/main/AnaliseDe_Student_addiction_Dataset_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "An√°lise de Dados sobre V√≠cios em Estudantes\n",
        "\n",
        "Introdu√ß√£o\n",
        "Este projeto visa analisar os padr√µes de comportamento relacionados a v√≠cios em estudantes utilizando t√©cnicas de clustering, an√°lise de componentes principais (PCA) e regress√£o linear. O objetivo √© identificar grupos distintos de estudantes com base em seus comportamentos e caracter√≠sticas."
      ],
      "metadata": {
        "id": "5EajfQ5EYmOI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "g96Hq7PQ0na8",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Importar bibiotecas necessarias"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparacao de dados,tratamento e limpeza\n",
        "Descri√ß√£o dos Dados O dataset cont√©m informa√ß√µes sobre comportamentos relacionados a v√≠cios em estudantes, incluindo experimenta√ß√£o, desempenho acad√™mico, isolamento social, problemas financeiros e de sa√∫de mental. Dados exportados do Kaggle."
      ],
      "metadata": {
        "id": "ybcpdiNQY3mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/student_addiction_dataset_test.csv') #Exportando os dados\n",
        "# Visualizar as primeiras linhas do DataFrame\n",
        "pd.set_option('display.max_columns', None)\n",
        "# Mapear 'N√ÉO' para False e 'SIM' para True em todas as colunas\n",
        "df = df.replace({'No': False, 'Yes': True})\n",
        "df.fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "gZHEqu5yXDuu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "2723c632-bfd4-4584-9f58-6c34d08b2c0e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/student_addiction_dataset_test.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-1b04d64d69b9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/student_addiction_dataset_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Exportando os dados\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# Visualizar as primeiras linhas do DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'display.max_columns'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Mapear 'N√ÉO' para False e 'SIM' para True em todas as colunas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'No'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Yes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/student_addiction_dataset_test.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analise exploratoria dos dados;\n",
        "Estatisticas descritivas e visualizacoes iniciais;\n",
        "Descricao de medias por grupos;\n",
        "Descricao de desvio padrao por grupos;\n",
        "Realizacao de tabela cruzada entre as colunas Experimentation e Addiction Class"
      ],
      "metadata": {
        "id": "9KDnxEU-ZOMi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grouped = df.groupby('Addiction_Class')\n",
        "mean_values = grouped.mean()\n",
        "std_values = grouped.std()\n",
        "print(mean_values, 'Mean values for each group')\n",
        "print(std_values, 'Standard deviation for each group')\n",
        "\n",
        "differences = []\n",
        "for column in df.columns:\n",
        "    counts = df[column].value_counts()\n",
        "    Sim_counts = counts.get(True, 0)\n",
        "    Nao_counts = counts.get(False, 0)\n",
        "    diff = Sim_counts - Nao_counts\n",
        "    differences.append((column, diff))\n",
        "\n",
        "cross_tab = pd.crosstab(df['Experimentation'], df['Addiction_Class'])\n",
        "print(cross_tab, 'Cross tabs Experimentation and Addiction')\n",
        "print(cross_tab.corr())"
      ],
      "metadata": {
        "id": "O0sOaWRmYUbw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "84af6f14-8fed-47ad-952a-3fe657e6f4bb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'df' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-1ed0d50656cf>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Addiction_Class'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmean_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstd_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrouped\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Mean values for each group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstd_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Standard deviation for each group'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalizacao dos dados\n"
      ],
      "metadata": {
        "id": "yvIAy9VGa-fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizando os dados\n",
        "scaler = StandardScaler()\n",
        "df_scaled = scaler.fit_transform(df)"
      ],
      "metadata": {
        "id": "rqJ8ppvBbr-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An√°lise de Clustering com K-Means e PCA\n",
        "MODELAGEM\n",
        "\n",
        "### Por que se ultiliza K-Means?\n",
        "O algoritmo de K-Means √© uma t√©cnica de aprendizado n√£o supervisionado usada para particionar um conjunto de dados em um n√∫mero pr√©-definido de clusters. Cada ponto de dado pertence ao cluster cujo centro est√° mais pr√≥ximo, resultando em uma divis√£o dos dados em grupos distintos. Esta abordagem √© √∫til quando queremos identificar subgrupos em nossos dados que possuem caracter√≠sticas similares, o que pode fornecer insights valiosos sobre padr√µes de comportamento ou caracter√≠sticas comuns entre diferentes grupos.\n",
        "\n",
        "### Processo de Clustering\n",
        "1. Normaliza√ß√£o dos Dados:\n",
        "   Antes de aplicar o K-Means, foi normalizado  os dados para garantir que todas as vari√°veis estejam na mesma escala. Isso √© feito utilizando `StandardScaler`, que transforma os dados para que tenham m√©dia zero e desvio padr√£o um."
      ],
      "metadata": {
        "id": "M7dJf252cADw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encontrando o melhor n√∫mero de clusters com o m√©todo do cotovelo\n",
        "sse = []\n",
        "k_range = range(1, 11)\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(df_scaled)\n",
        "    sse.append(kmeans.inertia_)"
      ],
      "metadata": {
        "id": "hIjcAcbFbuqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualicacao com Matplotlib para melhor entendimento\n"
      ],
      "metadata": {
        "id": "OTmdZe0FcNXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_range, sse, marker='o')\n",
        "plt.xlabel('N√∫mber of Clusters')\n",
        "plt.ylabel('SSE (Sum of square errors)')\n",
        "plt.title('Elbow method')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lMcac_KYcGJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplica√ß√£o do K-Means:\n",
        "Ap√≥s determinar o n√∫mero apropriado de clusters , aplicamos o K-Means para particionar os dados em clusters."
      ],
      "metadata": {
        "id": "pSd1595SejL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A partir do gr√°fico, escolha o n√∫mero apropriado de clusters (por exemplo, 3)\n",
        "num_clusters = 3\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans.fit(df_scaled)\n",
        "df['Cluster'] = kmeans.labels_"
      ],
      "metadata": {
        "id": "cFZ4M-XicSaE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "An√°lise de Componentes Principais (PCA)\n",
        "A PCA √© uma t√©cnica de redu√ß√£o de dimensionalidade que transforma um conjunto de vari√°veis correlacionadas em um conjunto menor de vari√°veis n√£o correlacionadas chamadas componentes principais. Esta abordagem √© √∫til para visualizar dados de alta dimens√£o em gr√°ficos de duas ou tr√™s dimens√µes, mantendo a maior parte da vari√¢ncia original dos dados.\n",
        "\n",
        "Aplica√ß√£o da PCA:\n",
        "Aplicamos a PCA para reduzir os dados a cinco componentes principais, o que facilita a visualiza√ß√£o e a an√°lise dos clusters."
      ],
      "metadata": {
        "id": "wRipOKZLe6dF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PCA com mais componentes\n",
        "pca = PCA(n_components=5)  # Aumentando o n√∫mero de componentes para 5\n",
        "principalComponents = pca.fit_transform(df_scaled)\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "print(\"Explained variance by component:\")\n",
        "print(explained_variance)\n",
        "num_columns = df.shape[1]\n",
        "# DataFrame dos componentes principais\n",
        "principal_df = pd.DataFrame(data=principalComponents, columns=[f'PC{i+1}' for i in range(5)])\n",
        "print(\"Principal components:\")\n",
        "components = pd.DataFrame(pca.components_, columns=df.columns[:-1], index=[f'PC{i+1}' for i in range(5)])\n",
        "print(components)"
      ],
      "metadata": {
        "id": "1vGS3DEheeLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualizacao dos clusters"
      ],
      "metadata": {
        "id": "tHMFuZOxgMH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizar os clusters nas primeiras duas componentes principais\n",
        "plt.scatter(principalComponents[:, 0], principalComponents[:, 1], c=df['Cluster'])\n",
        "plt.xlabel('PC1')\n",
        "plt.ylabel('PC2')\n",
        "plt.title('Clusters visualized on first two principal components')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HC2EbebjgHAU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ajustando o Modelo de K-Means com Mais Componentes Principais\n",
        "Ap√≥s a normaliza√ß√£o dos dados e a aplica√ß√£o do K-Means inicialmente, foi utilizado a An√°lise de Componentes Principais (PCA) para reduzir a dimensionalidade dos dados. A PCA transforma os dados originais em componentes principais que explicam a maior parte da varia√ß√£o nos dados. Usar mais componentes principais significa capturar mais variabilidade dos dados, o que pode levar a uma melhor separa√ß√£o entre os clusters.\n",
        "\n",
        "Isso permite que o modelo K-Means trabalhe com uma representa√ß√£o mais rica dos dados, que pode melhorar a qualidade do clustering.\n",
        "\n",
        "Motiva√ß√£o\n",
        "\n",
        "A principal motiva√ß√£o para ajustar o K-Means com mais componentes principais √© melhorar a qualidade do clustering. Componentes principais adicionais podem capturar mais vari√¢ncia nos dados, o que pode ajudar o K-Means a identificar padr√µes mais claros e formar clusters mais coesos. Al√©m disso, a utiliza√ß√£o de componentes principais reduzidos pode facilitar a visualiza√ß√£o e interpreta√ß√£o dos clusters.Como um melhor vizualizacao,e grupos mais distintos com menor dimensionalidade  e possivel inferir fatores de causalidade relacionados a eles\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VgAHGKsjjR2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ajustar o modelo de KMeans com mais componentes principais\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "df['Cluster'] = kmeans.fit_predict(principalComponents)"
      ],
      "metadata": {
        "id": "_EySdA61hBIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Interpreta√ß√£o das Distribui√ß√µes\n",
        "A partir dessas visualiza√ß√µes, voc√™ pode observar como cada vari√°vel se comporta dentro de cada cluster. Por exemplo:\n",
        "\n",
        "Experimentation: Pode-se observar que o n√≠vel de experimenta√ß√£o varia significativamente entre os clusters, indicando que alguns grupos de estudantes s√£o mais propensos a experimentar subst√¢ncias do que outros.\n",
        "Academic Performance Decline: A queda no desempenho acad√™mico pode ser mais pronunciada em alguns clusters, sugerindo uma correla√ß√£o entre certos tipos de v√≠cios e o impacto negativo no desempenho acad√™mico.\n",
        "Social Isolation: A an√°lise pode revelar que determinados clusters t√™m uma maior incid√™ncia de isolamento social, o que pode estar associado a comportamentos de v√≠cio."
      ],
      "metadata": {
        "id": "IvhMDD4YCEkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Analisando os clusters\n",
        "colunas = ['Experimentation', 'Academic_Performance_Decline', 'Social_Isolation', 'Financial_Issues', 'Physical_Mental_Health_Problems']\n",
        "for coluna in colunas:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.countplot(data=df, x=coluna, hue='Cluster', palette='viridis')\n",
        "    plt.title(f'Distribui√ß√£o de {coluna} por Cluster')\n",
        "    plt.xlabel(coluna)\n",
        "    plt.ylabel('Contagem')\n",
        "    plt.legend(title='Cluster')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "iYOlKRi_jao-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Silhouette Score\n",
        "O Silhouette Score √© uma m√©trica usada para avaliar a qualidade do clustering. Ele mede o qu√£o semelhante um ponto √© ao seu pr√≥prio cluster em compara√ß√£o com outros clusters."
      ],
      "metadata": {
        "id": "wybtbm3F-9fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Silhouette Score com mais componentes principais\n",
        "score = silhouette_score(principalComponents, df['Cluster'])\n",
        "print(f'Silhouette Score with more components: {score}')"
      ],
      "metadata": {
        "id": "YKv27ESetDKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Regress√£o Linear com Componentes Principais e Valida√ß√£o Cruzada\n",
        "Objetivo\n",
        "O objetivo desta parte da an√°lise √© ajustar um modelo de regress√£o linear para prever a classe de v√≠cio (Addiction_Class) com base nas componentes principais obtidas a partir da PCA. Al√©m disso, usamos valida√ß√£o cruzada (cross-validation) para avaliar a performance do modelo."
      ],
      "metadata": {
        "id": "e6e3g4xqDPig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Regress√£o Linear com mais componentes principais\n",
        "#Prepara√ß√£o dos Dados para Regress√£o:\n",
        "#X s√£o as componentes principais obtidas da PCA.\n",
        "#y √© a vari√°vel alvo, Addiction_Class.\n",
        "model = LinearRegression()\n",
        "X = principalComponents\n",
        "y = df['Addiction_Class']\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "ByVZEHOwCYQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Valida√ß√£o Cruzada (Cross-Validation):\n",
        "Utilizamos a t√©cnica de valida√ß√£o cruzada com 5 folds (cv=5) para avaliar a performance do modelo de regress√£o linear.\n",
        "A valida√ß√£o cruzada divide os dados em 5 partes. Em cada itera√ß√£o, uma parte √© usada como conjunto de teste e as outras quatro como conjunto de treinamento. Este processo √© repetido 5 vezes, com cada parte sendo usada uma vez como conjunto de teste.\n",
        "cross_val_score √© utilizado para calcular as m√©tricas de avalia√ß√£o (neste caso, o coeficiente de determina√ß√£o\n",
        "ùëÖ\n",
        "2\n",
        "R\n",
        "2\n",
        " ) para cada itera√ß√£o."
      ],
      "metadata": {
        "id": "xnaRtC_sDiTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Cross Validation com mais componentes principais\n",
        "scores = cross_val_score(model, X, y, cv=5)\n",
        "print(f'Cross-validation scores with more components: {scores}')\n",
        "print(f'Average cross-validation score with more components: {np.mean(scores)}')"
      ],
      "metadata": {
        "id": "DIuKGWb-De8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Agrupando por cluster e calculando a m√©dia para cada caracter√≠stica\n",
        "cluster_means = df.groupby('Cluster').mean()\n",
        "print(cluster_means)"
      ],
      "metadata": {
        "id": "1tQv0pY_FXwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correla√ß√£o entre Vari√°veis para cada Cluster e Visualiza√ß√µes\n",
        "Objetivo\n",
        "O objetivo dessa parte da an√°lise √© entender a rela√ß√£o entre diferentes vari√°veis dentro de cada cluster. A correla√ß√£o entre vari√°veis pode fornecer insights sobre como os fatores se relacionam entre si dentro dos clusters identificados pelo KMeans.\n",
        "\n",
        "Passos Detalhados\n",
        "Agrupamento por Cluster:\n",
        "\n",
        "Os dados s√£o agrupados por cluster para realizar a an√°lise de correla√ß√£o dentro de cada grupo.\n",
        "Matriz de Correla√ß√£o:\n",
        "\n",
        "A matriz de correla√ß√£o √© calculada para cada cluster usando o m√©todo corr() do pandas. Esta matriz mostra a correla√ß√£o entre cada par de vari√°veis.\n",
        "Uma correla√ß√£o alta (perto de 1 ou -1) indica uma forte rela√ß√£o linear entre duas vari√°veis, enquanto uma correla√ß√£o baixa (perto de 0) indica pouca ou nenhuma rela√ß√£o linear.\n",
        "Visualiza√ß√£o com Heatmap:\n",
        "\n",
        "Usamos sns.heatmap do Seaborn para visualizar a matriz de correla√ß√£o. O heatmap √© uma representa√ß√£o gr√°fica onde cores mais escuras indicam correla√ß√µes mais fortes (positivas ou negativas)."
      ],
      "metadata": {
        "id": "TLJd2tNNHBPm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para cada cluster, calcular as correla√ß√µes entre as vari√°veis\n",
        "for cluster in df['Cluster'].unique():\n",
        "    df_cluster = df[df['Cluster'] == cluster]\n",
        "    correlation_matrix = df_cluster.corr()\n",
        "    print(correlation_matrix)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "    plt.title(f'Heatmap de Correla√ß√£o - Cluster {cluster}')\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "znaWCnCIFetx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conclus√µes\n",
        "Predomin√¢ncia de N√£o Experimenta√ß√£o (0): Em todos os clusters, a maioria dos estudantes n√£o experimentou a subst√¢ncia (0). Isso pode sugerir que a experimenta√ß√£o n√£o √© o comportamento dominante na maioria dos estudantes analisados.\n",
        "Cluster 2 Tem a Maior Popula√ß√£o de N√£o Experimentadores: O cluster 2 destaca-se por ter o maior n√∫mero de estudantes que n√£o experimentaram, indicando que esse cluster pode estar mais associado a comportamentos mais conservadores ou menos propensos √† experimenta√ß√£o.\n",
        "Menor Varia√ß√£o Entre Clusters Para Experimenta√ß√£o (1): Embora todos os clusters tenham uma quantidade menor de estudantes que experimentaram (1), as propor√ß√µes parecem relativamente similares, sugerindo que a experimenta√ß√£o √© um comportamento menos comum e, portanto, menos discriminativo entre os clusters."
      ],
      "metadata": {
        "id": "I_01rheXJtaT"
      }
    }
  ]
}